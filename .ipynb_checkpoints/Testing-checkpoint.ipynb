{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore'); #tensorflow gives me weird stuff\n",
    "import numpy as np;\n",
    "import tensorflow as tf;\n",
    "from numpy import matmul as mul\n",
    "from numpy.linalg import norm as norm\n",
    "from scipy import sparse\n",
    "from tensorflow.sparse import to_dense\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hadamard product\n",
    "\n",
    "def hadamard(matrices, skip_matrix = -1):\n",
    "    #matrices is a list of numpy ndarrays (shape of all matrices must be the same)\n",
    "    shp = matrices[0].shape\n",
    "    #Commented out for performance increase\n",
    "#     for m in matrices: \n",
    "#         if m.shape != shp:\n",
    "#             return None\n",
    "    ret = np.ones(shp)\n",
    "    for i in range(shp[0]):\n",
    "        for j in range(shp[1]):\n",
    "            for num,k in enumerate(matrices):\n",
    "                if(num != skip_matrix):\n",
    "                    ret[i][j] *= k[i][j]\n",
    "                    if ret[i][j] == 0: #just a lil optimization\n",
    "                        break;\n",
    "    return ret\n",
    "\n",
    "#MTTKRP helper methods\n",
    "\n",
    "def calc_indices(t, dims, n):\n",
    "    #t is the target row we want (zero indexed)\n",
    "    #dims is the dimensions of the tensor\n",
    "    #n is the factor matrix we dont want to include\n",
    "    \n",
    "    #first get cumulative products on our factors\n",
    "    prods = [1]\n",
    "    nd = len(dims)\n",
    "    for i in range(nd-1,-1,-1):\n",
    "        if i!=n:\n",
    "            p = prods[-1] * dims[i]\n",
    "            prods.append(p)\n",
    "    prods.reverse()\n",
    "    prods = prods[1:]\n",
    "    ret = [] #the coefficients of the thingy we want\n",
    "    for i in range(nd - 1):\n",
    "        n = t // prods[i];\n",
    "        ret.append(n)\n",
    "        t -= (prods[i] * n)\n",
    "    return ret\n",
    "\n",
    "def khatri_rao_at_ij(factors, i, j, dims, n):\n",
    "    #dims is the list of dimensions, factors is the actual factor matrix, \n",
    "    #factors is the list of all factor matrices\n",
    "    #gives you the khatri rao product at a certain index\n",
    "    product = 1\n",
    "    i_vals = calc_indices(i, dims, n)\n",
    "    for num, factor in enumerate(factors):\n",
    "        if num == n:\n",
    "            pass\n",
    "        if num < n:\n",
    "            product *= factors[num][i_vals[num]][j]\n",
    "        if num > n:\n",
    "            product *= factors[num][i_vals[num-1]][j]\n",
    "    return product\n",
    "\n",
    "def find_index_unfolded(dims, n, idx):\n",
    "    #finds the coordinates of the unfolded tensor element given the coordinates of the not-unfolded tensor\n",
    "    j = 0;\n",
    "    nd = len(dims)\n",
    "    prod = 1;\n",
    "    \n",
    "    for i in range(nd):\n",
    "        if i != n:\n",
    "            j += idx[i] * prod\n",
    "            prod *= dims[i]\n",
    "    \n",
    "    return (idx[n], j)\n",
    "\n",
    "def MTTKRP(X, factors, weights, n,rank,dims):\n",
    "    # Matricized Tensor Times Khatri Rao Product\n",
    "    # X unfolded is short and fat, khatri-rao is tall and skinny\n",
    "    # output is short and skinny\n",
    "    \n",
    "    nd = len(dims)\n",
    "    output = np.zeros((dims[n],rank))\n",
    "    indices = X.indices.numpy()\n",
    "    values = X.values.numpy()\n",
    "    \n",
    "    for l in range(len(values)):\n",
    "        cur_index = indices[l]\n",
    "        cur_value = values[l]\n",
    "        i,j = find_index_unfolded(dims, n, cur_index) \n",
    "        # gets the index of this element if we did a mode n unfolding of X\n",
    "        \n",
    "        for r in range(rank):\n",
    "            output[i][r] += cur_value * khatri_rao_at_ij(factors,j,r,dims,n) * weights[0][r]\n",
    "            \n",
    "    return output\n",
    "\n",
    "def cp_als(X, rank, iterations = 3):\n",
    "    \n",
    "    dims = X.shape.as_list()\n",
    "    nd = len(dims)\n",
    "    factors = [np.random.random((d,rank)) for d in dims]\n",
    "    l = np.ones((1,rank))\n",
    "    \n",
    "    for iteration in range(iterations): \n",
    "        for n in range(nd):\n",
    "            to_be_hadamarded = [mul(f.T,f) for f in factors] + [mul(l.T,l)]\n",
    "            v = hadamard(to_be_hadamarded, skip_matrix=n)   \n",
    "            vinv = np.linalg.pinv(v)\n",
    "            mk = MTTKRP(X, factors, l, n, rank, dims)\n",
    "            An = mul(mk,vinv)\n",
    "            for i in range(rank):\n",
    "                col = An[:,i]\n",
    "                weight = norm(col)\n",
    "                # print( \" weight: \", weight, 'col: ', col)\n",
    "                if(abs(weight)> 0.000001):\n",
    "                    An[:,i]/=weight\n",
    "                    l[0][i]*=weight\n",
    "            factors[n] = An\n",
    "            \n",
    "    return l, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(factors, weights, dim_no, cur_idx, cur_prod, all_vals, rank):\n",
    "    #this method just writes to all values, so all values needs to be saved somewhere\n",
    "    if dim_no == len(factors):\n",
    "        value = 0;\n",
    "        for r in range(rank):\n",
    "            value += cur_prod[r] * weights[0][r]\n",
    "        if(value != 0.0):\n",
    "            all_vals.append((cur_idx,value)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)): # go through all rows\n",
    "            cp = np.ndarray.copy(cur_prod);\n",
    "            for r in range(rank): # go through each rank\n",
    "                cp[r] *= cur_fact[i][r]\n",
    "            expand(factors, weights, dim_no + 1, cur_idx + [i], cp, all_vals, rank)\n",
    "            \n",
    "def rebuild_sp_tensor_from_factors(kruskal_tensor, dimensions, rank):\n",
    "    factors = kruskal_tensor[1]\n",
    "    weights = kruskal_tensor[0]\n",
    "    all_values = []\n",
    "    expand(factors, weights, 0, [], np.ones(rank), all_values, rank)\n",
    "    indices = [a[0] for a in all_values]\n",
    "    values = [a[1] for a in all_values]\n",
    "    shape = dimensions\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_factors(dimensions, rank, d = 0.9):\n",
    "    factors = [sparse.random(dim,rank,density=d).A for dim in dimensions]\n",
    "    return factors\n",
    "\n",
    "def expand_random_factors(factors, dim_no, cur_idx, cur_prod, all_vals, rank):\n",
    "    #this method just writes to all values, so all values needs to be saved somewhere\n",
    "    if dim_no == len(factors):\n",
    "        value = sum(cur_prod) * (3.16**dim_no) # root 10. makes the numbers closer to [0-1]\n",
    "        if(value != 0.0):\n",
    "            all_vals.append((cur_idx,value)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)):\n",
    "            cp = np.ndarray.copy(cur_prod);\n",
    "            for r in range(rank):\n",
    "                cp[r] *= cur_fact[i][r]\n",
    "            expand_random_factors(factors, dim_no + 1, cur_idx + [i], cp, all_vals, rank)\n",
    "            \n",
    "def generate_decomposable_sp_tensor(dimensions, rank):\n",
    "    factors = generate_random_factors(dimensions, rank)\n",
    "    all_values = []\n",
    "    expand_random_factors(factors, 0, [], np.ones(rank), all_values, rank)\n",
    "    indices = [a[0] for a in all_values]\n",
    "    values = [a[1] for a in all_values]\n",
    "    shape = dimensions\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    return st\n",
    "\n",
    "def generate_random_sp_tensor(dimensions, d = 0.2):\n",
    "    nd = len(dimensions)\n",
    "    num_items = min(100000 , (int)(np.prod(dimensions) * d))    \n",
    "    idxs = set()\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        rand = np.random.rand(nd) #gives us a random index\n",
    "        index = tuple(np.trunc(np.multiply(rand,dimensions)).astype(int))\n",
    "        idxs.add(index)\n",
    "        \n",
    "    indices = list(idxs)\n",
    "    values = np.random.rand(len(indices))\n",
    "    indices.sort()\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=dimensions)\n",
    "    return st\n",
    "\n",
    "def generate_sp_tensor(dimensions, rank, d = 0.2, decomposable=True):\n",
    "    if decomposable:\n",
    "        return generate_decomposable_sp_tensor(dimensions, rank)\n",
    "    else:\n",
    "        return generate_random_sp_tensor(dimensions,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_norm(st):\n",
    "    return (sum([x**2 for x in st.values.numpy()])**0.5)\n",
    "\n",
    "def difference_frobenius_norm(spt1, spt2):\n",
    "    idx1 = [tuple(s) for s in spt1.indices.numpy()]\n",
    "    idx2 = [tuple(s) for s in spt2.indices.numpy()]\n",
    "    val1 = spt1.values.numpy()\n",
    "    val2 = spt2.values.numpy() \n",
    "    s1 = {idx1[i]:val1[i] for i in range(len(idx1))}\n",
    "    s2 = {idx2[i]:val2[i] for i in range(len(idx2))}\n",
    "    sum_sq = 0;\n",
    "    for i in idx1:\n",
    "        if i in idx2:\n",
    "            sum_sq += (s1[i] - s2[i]) ** 2\n",
    "        else:\n",
    "            sum_sq += s1[i] ** 2\n",
    "    for i in idx2:\n",
    "        if i in idx1:\n",
    "            sum_sq += 0\n",
    "        else:\n",
    "            sum_sq += s2[i] ** 2\n",
    "    return sum_sq ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4114, shape=(4, 3, 2), dtype=float64, numpy=\n",
       "array([[[ 9.11241802, 10.83265817],\n",
       "        [13.3053546 , 16.25679266],\n",
       "        [ 5.87618209,  7.15805067]],\n",
       "\n",
       "       [[ 1.08570583,  1.3252652 ],\n",
       "        [16.93689772,  7.37834232],\n",
       "        [11.89342612,  2.99107915]],\n",
       "\n",
       "       [[11.3940467 , 13.50234465],\n",
       "        [16.02329659, 13.61712911],\n",
       "        [ 9.20197785,  6.31354907]],\n",
       "\n",
       "       [[15.7493738 , 18.69227253],\n",
       "        [31.87314398, 23.33773793],\n",
       "        [19.43137579, 10.5012696 ]]])>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape1 = [4,3,2]\n",
    "rank = 3\n",
    "st1 = generate_sp_tensor(shape1, rank)\n",
    "to_dense(st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[137527.11170309, 111376.12166951,  26450.08662432]]),\n",
       " [array([[-0.31432873, -0.31429734,  0.31451624],\n",
       "         [-0.38918162, -0.38916189,  0.38930888],\n",
       "         [-0.3975168 , -0.39753945,  0.3973753 ],\n",
       "         [-0.76923047, -0.76924157,  0.76916253]]),\n",
       "  array([[-0.75253328,  0.75270854, -0.75143464],\n",
       "         [-0.56882667,  0.56872221, -0.5694843 ],\n",
       "         [-0.33185822,  0.33163972, -0.33321706]]),\n",
       "  array([[-0.48762111, -0.46191474, -0.59193798],\n",
       "         [-0.87305535, -0.88692433, -0.80598351]])])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpd = cp_als(st1, rank, 100)\n",
    "cpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=4721, shape=(4, 3, 2), dtype=float64, numpy=\n",
       "array([[[ 8.34350438,  6.25919187],\n",
       "        [ 9.8033024 ,  7.35249567],\n",
       "        [ 7.97396529,  5.93664291]],\n",
       "\n",
       "       [[ 9.83687414,  7.49144839],\n",
       "        [11.76210096,  8.90438204],\n",
       "        [ 9.65189747,  7.23178953]],\n",
       "\n",
       "       [[ 8.51093574,  6.48532713],\n",
       "        [10.84566374,  8.20368722],\n",
       "        [ 9.17249777,  6.86031283]],\n",
       "\n",
       "       [[17.62404781, 13.41393425],\n",
       "        [21.86528523, 16.53543324],\n",
       "        [18.2652183 , 13.66548676]]])>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt = rebuild_sp_tensor_from_factors(cpd, shape1, rank)\n",
    "to_dense(rebuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.265435072589977"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_frobenius_norm(st1, rebuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68.89697094818669"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_norm(st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
