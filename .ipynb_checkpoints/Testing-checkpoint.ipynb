{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore'); #tensorflow gives me weird stuff\n",
    "import numpy as np;\n",
    "import tensorflow as tf;\n",
    "from numpy import matmul as mul\n",
    "from numpy.linalg import norm as norm\n",
    "from scipy import sparse\n",
    "from tensorflow.sparse import to_dense\n",
    "from numba import prange,njit,jit\n",
    "from numba.typed import List\n",
    "from datetime import datetime\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def expand(factors, weights, dim_no, cur_idx, all_vals, rank):\n",
    "    \n",
    "    if dim_no == len(factors):\n",
    "#         print(cur_idx)\n",
    "        value = np.ones(rank)\n",
    "        for j,w in enumerate(weights):                \n",
    "            value[j] = w\n",
    "        for i in range(dim_no):\n",
    "            ci = cur_idx[i]\n",
    "            f = factors[i][ci]\n",
    "            for j,v in enumerate(value):                \n",
    "                value[j] = v * f[j]\n",
    "        s = 0.0\n",
    "        for val in value:\n",
    "            s += val\n",
    "        if(s != 0.0):\n",
    "            t = np.ones(dim_no, dtype=np.int64)\n",
    "            for k in range(dim_no):\n",
    "                t[k] = cur_idx[k]\n",
    "            all_vals.append((t,s)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)):\n",
    "            cur_idx[dim_no] = i\n",
    "            expand(factors, weights, dim_no + 1, cur_idx, all_vals, rank)\n",
    "\n",
    "def rebuild(kruskal_tensor, dimensions, rank):\n",
    "    factors = kruskal_tensor[1]\n",
    "    weights = kruskal_tensor[0][0]\n",
    "    cur_idx = np.zeros(len(dimensions), dtype=\"int64\")\n",
    "    av = [(cur_idx, 0.0)] # list(Tuple(array(int64, 1d, C), float64)))\n",
    "    \n",
    "    expand(factors, weights, 0, cur_idx, av, rank)\n",
    "    \n",
    "    av = av[1:]\n",
    "    indexes = [a[0] for a in av]\n",
    "    vals = [a[1] for a in av]\n",
    "#     print(indexes)\n",
    "#     print(vals)\n",
    "    st = tf.SparseTensor(indices=indexes, values=vals, dense_shape=dimensions)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_factors(dimensions, rank, d = 0.1):\n",
    "    factors = [sparse.random(dim,rank,density=d).A for dim in dimensions]\n",
    "    return factors\n",
    "\n",
    "@njit(parallel=True)\n",
    "def l1_erf(factors, cur_idx, all_vals, rank):\n",
    "    cur_fact = factors[0]\n",
    "    for i in prange(len(cur_fact)):\n",
    "        cur_idx[0] = i\n",
    "        expand_random_factors(factors, 1, cur_idx, all_vals, rank)\n",
    "        \n",
    "@njit\n",
    "def expand_random_factors(factors, dim_no, cur_idx, all_vals, rank):\n",
    "    #this method just writes to all values, so all values needs to be saved somewhere\n",
    "    if dim_no == len(factors):\n",
    "        value = np.ones(rank)\n",
    "        for i in range(dim_no):\n",
    "            ci = cur_idx[i]\n",
    "            f = factors[i][ci]\n",
    "            for j,v in enumerate(value):                \n",
    "                value[j] = v * f[j]\n",
    "        s = 0.0\n",
    "        for val in value:\n",
    "            s += val\n",
    "        v = s * (3.16**dim_no)\n",
    "        if(v != 0.0):\n",
    "            t = np.ones(dim_no, dtype=np.int64)\n",
    "            t *= cur_idx\n",
    "            all_vals.append((t,v)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)):\n",
    "            cur_idx[dim_no] = i\n",
    "            expand_random_factors(factors, dim_no + 1, cur_idx, all_vals, rank)\n",
    "            \n",
    "def generate_decomposable_sp_tensor(dimensions, rank, d = 0.1):\n",
    "    nd = len(dimensions)\n",
    "    factor_d = (d/rank) ** (1/nd)\n",
    "    \n",
    "    factors = generate_random_factors(dimensions, rank, factor_d)\n",
    "    cur_idx = np.zeros(len(dimensions), dtype=\"int64\")\n",
    "    all_values = [(cur_idx, 0.0)] # list(Tuple(array(int64, 1d, C), float64)))\n",
    "    expand_random_factors(factors, 0, cur_idx, all_values, rank)\n",
    "    all_values = all_values[1:]\n",
    "    indices = [a[0] for a in all_values]\n",
    "    values = [a[1] for a in all_values]\n",
    "    shape = dimensions\n",
    "#     print(indices)\n",
    "#     print(values)\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    return st\n",
    "\n",
    "def generate_random_sp_tensor(dimensions, d = 0.2):\n",
    "    nd = len(dimensions)\n",
    "    num_items = min(100000 , (int)(np.prod(dimensions) * d))    \n",
    "    idxs = set()\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        rand = np.random.rand(nd) #gives us a random index\n",
    "        index = tuple(np.trunc(np.multiply(rand,dimensions)).astype(int))\n",
    "        idxs.add(index)\n",
    "        \n",
    "    indices = list(idxs)\n",
    "    values = np.random.rand(len(indices))\n",
    "    indices.sort()\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=dimensions)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_norm(st):\n",
    "    return (sum([x**2 for x in st.values.numpy()])**0.5)\n",
    "\n",
    "def diff(spt1, spt2):\n",
    "    idx1 = [tuple(s) for s in spt1.indices.numpy()]\n",
    "    idx2 = [tuple(s) for s in spt2.indices.numpy()]\n",
    "    val1 = spt1.values.numpy()\n",
    "    val2 = spt2.values.numpy() \n",
    "    s1 = [(idx1[i],val1[i]) for i in range(len(idx1))]\n",
    "    s2 = [(idx2[i],val2[i]) for i in range(len(idx2))]\n",
    "    s1.sort()\n",
    "    s2.sort()\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    l1 = len(s1)\n",
    "    l2 = len(s2)\n",
    "    \n",
    "    sum_sq = 0\n",
    "    while(i1 < l1 and i2 < l2):\n",
    "        p1 = s1[i1]\n",
    "        p2 = s2[i2]\n",
    "        if p1[0] == p2[0]:\n",
    "            sum_sq += (p1[1] - p2[1]) ** 2\n",
    "            i1 += 1\n",
    "            i2 += 1\n",
    "        elif p1[0] < p2[0]:\n",
    "            sum_sq += p1[1] ** 2\n",
    "            i1 += 1\n",
    "        else:\n",
    "            sum_sq += p2[1] ** 2\n",
    "            i2 += 1\n",
    "    if(i1 == l1):\n",
    "        while(i2 < l2):\n",
    "            p2 = s2[i2]\n",
    "            sum_sq += p2[1] ** 2\n",
    "            i2 += 1\n",
    "    else:\n",
    "        while(i1 < l1):\n",
    "            p1 = s1[i1]\n",
    "            sum_sq += p1[1] ** 2\n",
    "            i1 += 1\n",
    "            \n",
    "    return sum_sq ** 0.5\n",
    "            \n",
    "def fit(spt1,spt2):\n",
    "    return 1 - (diff(spt1,spt2)/tensor_norm(spt1))\n",
    "\n",
    "def easy_fit(spt1,spt2):\n",
    "    return 1 - (abs(tensor_norm(spt1)-tensor_norm(spt2))/tensor_norm(spt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mttkrp2(X, factors, n, rank, dims):    \n",
    "    output = np.zeros((dims[n],rank))\n",
    "    indices = X.indices.numpy()\n",
    "    values = X.values.numpy()\n",
    "    \n",
    "    for l in prange(len(values)):\n",
    "        cur_index = indices[l]\n",
    "        prod = [values[l]]*rank #makes the value into a row\n",
    "\n",
    "        for mode,cv in enumerate(cur_index): #does elementwise row multiplications\n",
    "            if(mode != n):\n",
    "                prod *= factors[mode][cv]      \n",
    "        output[cur_index[n]] += prod\n",
    "    \n",
<<<<<<< HEAD
    "    return output\n",
    "\n",
    "\n",
=======
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def mttkrp(values, indices, factors, n, rank, dims):    \n",
    "    output = np.zeros((dims[n],rank))\n",
    "\n",
    "    for l in prange(len(values)):\n",
    "        cur_index = indices[l]\n",
    "        prod = [values[l]]*rank #makes the value into a row\n",
    "\n",
    "        for mode,cv in enumerate(cur_index): #does elementwise row multiplications\n",
    "            if(mode != n):\n",
    "                for r in range(rank):\n",
    "                    prod[r] *= factors[mode][cv][r]\n",
    "            \n",
    "        for r in range(rank):\n",
    "            output[cur_index[n]][r] += prod[r]       \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
>>>>>>> 688865f04aff03f46b82626f7f5095bc4c4908c6
    "# CP Decomposition\n",
    "\n",
    "def cp_als(X, rank, n_iter_max = 50):\n",
    "    \n",
    "    dims = X.shape.as_list()\n",
    "    nd = len(dims)\n",
    "    factors = [np.random.random((d,rank)) for d in dims]\n",
    "    weights = np.ones((1,rank))\n",
    "    \n",
    "    for iteration in range(n_iter_max): \n",
    "#         print(iteration+1 , end=\"\\r\")\n",
    "        for n in range(nd):\n",
    "            \n",
    "            #the following block calculates inverse of the hadamard product\n",
    "            h = mul(weights.T,weights)\n",
    "            for i,f in enumerate(factors):\n",
    "                if i != n:\n",
    "                    h *= mul(f.T,f)\n",
    "            vinv = np.linalg.pinv(h)\n",
    "            \n",
    "            #the following block calculates An by doing MTTKRP and multiplying it by the inverse of the hadamard\n",
    "            vals = X.values.numpy()\n",
    "            idxs = X.indices.numpy()\n",
    "            mk = mttkrp(vals, idxs, factors, n, rank, dims)\n",
    "#             mk = mttkrp2(X, factors, n, rank, dims)\n",
    "            wmk = np.multiply(mk, weights[0]) #handling the weights\n",
    "            An = mul(wmk,vinv)\n",
    "            \n",
    "            #the following block normalizes the columns and stored\n",
    "            weight = norm(An,axis=0)\n",
    "            b = np.where(weight<1e-12, 1, weight)\n",
    "            weights[0] *= b\n",
    "            An /= b\n",
    "            \n",
    "            factors[n] = An\n",
    "            \n",
    "    return weights, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
<<<<<<< HEAD
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1 = [18,27,12]\n",
    "rank = 5\n",
    "st1 = generate_decomposable_sp_tensor(shape1, rank)\n",
    "#st1 = generate_random_sp_tensor(shape1)\n",
    "# to_dense(st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
=======
>>>>>>> 688865f04aff03f46b82626f7f5095bc4c4908c6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time:  1  seconds\n",
      "actual density:  0.17483333333333334  vs given density  0.2\n"
     ]
    }
   ],
   "source": [
    "shape = (20,30,50)\n",
    "rank = 19\n",
    "density = 0.2\n",
    "before = datetime.now()\n",
    "st = generate_decomposable_sp_tensor(shape, rank, d=density)\n",
    "after = datetime.now()\n",
    "print(\"time: \",  (after-before).seconds, \" seconds\")\n",
    "print(\"actual density: \", st.values.shape[0]/np.prod(shape), \" vs given density \", density)\n",
    "# st = generate_random_sp_tensor(shape, rank)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 29,
>>>>>>> 688865f04aff03f46b82626f7f5095bc4c4908c6
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< HEAD
      "49\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[251.54445011, 543.37518739, 395.5193396 , 377.36487052,\n",
       "         239.62399279]]),\n",
       " [array([[ 4.62650493e-01,  3.44584764e-01,  4.26079186e-01,\n",
       "           1.34028881e-01, -4.55688273e-04],\n",
       "         [ 2.09866647e-01,  2.85996930e-01,  3.49713926e-01,\n",
       "           2.00117316e-02,  9.42391948e-02],\n",
       "         [ 2.93622476e-05,  1.22200083e-05,  1.68455908e-01,\n",
       "           3.51882693e-01,  2.78689015e-01],\n",
       "         [ 1.46415398e-01,  6.21829731e-02,  2.87879761e-01,\n",
       "           2.48213191e-01,  5.14805454e-02],\n",
       "         [ 2.87362401e-02,  2.96742623e-01,  3.41672157e-01,\n",
       "           1.27559948e-02,  1.31328769e-02],\n",
       "         [ 7.32431435e-05,  1.94443471e-01,  3.80259730e-02,\n",
       "           3.38872511e-01,  3.82095173e-01],\n",
       "         [ 1.02696994e-01,  2.36325660e-01,  1.39134226e-01,\n",
       "           2.02912588e-01,  1.82215645e-01],\n",
       "         [ 1.66325130e-01,  3.01225374e-01,  1.97211082e-01,\n",
       "           1.90311821e-01, -2.15808181e-04],\n",
       "         [-4.28780406e-05,  3.52848027e-01,  2.26295177e-01,\n",
       "           2.02717780e-01,  5.48069280e-02],\n",
       "         [ 8.30275282e-02,  4.16520584e-05,  2.62555383e-04,\n",
       "           7.26123863e-02,  3.11781216e-01],\n",
       "         [ 8.87311627e-05,  3.32804153e-01,  8.18437365e-04,\n",
       "           3.50566041e-01,  4.41847846e-01],\n",
       "         [-5.75031780e-05,  1.61013571e-01,  2.72516580e-01,\n",
       "           1.67128073e-01,  9.47984864e-02],\n",
       "         [ 4.04039953e-01,  1.53772041e-01,  5.44298739e-04,\n",
       "           3.08754612e-01,  2.68505332e-05],\n",
       "         [ 4.96422744e-01,  6.88801986e-02,  2.29953789e-01,\n",
       "           3.62675029e-01, -1.56564904e-04],\n",
       "         [ 4.94821239e-01,  7.24376452e-05,  6.25374706e-04,\n",
       "           2.96962964e-01,  2.98404792e-01],\n",
       "         [ 5.71644988e-02,  2.97020606e-01,  2.72952232e-01,\n",
       "           1.13467630e-01,  4.54715292e-01],\n",
       "         [ 1.29395894e-01,  3.27320598e-01,  3.94474597e-01,\n",
       "           2.77264620e-01,  2.44977018e-01],\n",
       "         [ 2.19404249e-05,  1.95482313e-01,  2.68975253e-04,\n",
       "           4.26568923e-02,  2.66789041e-01]]),\n",
       "  array([[ 3.66651084e-05,  2.73032057e-01,  3.78410785e-04,\n",
       "           2.23992468e-01, -3.25997512e-05],\n",
       "         [ 7.06868699e-03,  2.27044939e-01,  2.07717386e-04,\n",
       "           4.03111896e-02, -1.45748844e-01],\n",
       "         [ 1.53102072e-02,  1.37270523e-01,  2.21269908e-01,\n",
       "           3.22724278e-01,  8.54654980e-05],\n",
       "         [ 4.78794882e-02, -1.06732562e-04,  3.48422187e-01,\n",
       "           2.34162124e-01,  2.01764012e-04],\n",
       "         [ 3.24808361e-01,  2.00675201e-01,  2.74798962e-04,\n",
       "           7.35302747e-02, -1.06377150e-01],\n",
       "         [ 1.26407180e-01, -3.61955155e-06,  2.35525493e-01,\n",
       "           3.56082711e-01, -3.28896767e-01],\n",
       "         [ 2.63790623e-01,  2.86743628e-01,  4.02861862e-02,\n",
       "           6.50253000e-02, -2.92793267e-01],\n",
       "         [ 3.50653757e-01,  2.79166501e-01,  1.56289399e-01,\n",
       "           2.36924598e-01, -3.96203880e-01],\n",
       "         [ 1.04379943e-02,  1.88454237e-01,  1.07847631e-01,\n",
       "           1.12075827e-02, -7.98055540e-02],\n",
       "         [ 2.43849260e-01,  1.96807453e-01,  1.09902663e-01,\n",
       "           2.73544740e-01,  3.22873382e-05],\n",
       "         [ 3.06236547e-01,  7.76202838e-03,  1.95156601e-01,\n",
       "          -2.98057476e-04, -7.49998769e-02],\n",
       "         [ 8.44136314e-03,  1.08978943e-05,  5.55672850e-02,\n",
       "           1.58987084e-01, -1.09686145e-01],\n",
       "         [ 1.74833294e-01,  1.17624394e-01,  3.19902839e-01,\n",
       "           3.69614457e-01, -3.15971358e-01],\n",
       "         [ 1.54962726e-01,  4.50472162e-05,  2.38111710e-04,\n",
       "           8.22966999e-02, -2.42465850e-01],\n",
       "         [ 8.64724281e-02,  1.13360664e-01,  5.54744598e-02,\n",
       "           1.88383448e-01, -2.88925184e-06],\n",
       "         [ 5.12227803e-05,  2.50099510e-01,  9.04602598e-02,\n",
       "           3.56274258e-01, -3.00117309e-01],\n",
       "         [ 3.25074599e-01,  2.71930651e-01,  1.28121784e-01,\n",
       "          -2.32604805e-04,  1.81476990e-04],\n",
       "         [-1.95087115e-05,  2.57190720e-01,  5.77829681e-02,\n",
       "          -1.35977127e-04, -2.79516404e-01],\n",
       "         [ 3.52958764e-01,  1.92834199e-01,  1.42999366e-01,\n",
       "           4.58037224e-02, -8.94679302e-02],\n",
       "         [ 6.51508863e-02,  2.09874919e-01,  3.39412034e-01,\n",
       "           1.07181428e-01, -7.01094422e-02],\n",
       "         [ 4.96621369e-03,  1.51131661e-01,  6.84329486e-05,\n",
       "          -1.97407352e-05, -1.55619610e-02],\n",
       "         [ 1.61979197e-01,  3.01003202e-01,  1.01189947e-01,\n",
       "           2.23037525e-01,  6.59682318e-05],\n",
       "         [ 2.45654589e-02,  1.76732452e-01,  2.06957484e-01,\n",
       "          -3.02529867e-04, -5.86408715e-03],\n",
       "         [ 2.18186064e-01,  1.12578195e-01,  2.53856178e-01,\n",
       "           3.46043003e-01, -9.24551283e-02],\n",
       "         [ 2.49134992e-01,  2.75065145e-01,  3.29536637e-01,\n",
       "           8.68438248e-02, -3.29240857e-01],\n",
       "         [ 2.05254076e-01,  1.91706973e-01,  2.47041135e-01,\n",
       "          -3.95448751e-04, -2.20950610e-01],\n",
       "         [ 2.33994098e-01, -8.68430777e-05,  3.56506594e-01,\n",
       "          -5.30535691e-04, -2.94528705e-01]]),\n",
       "  array([[ 5.25435304e-01, -5.36604400e-05,  4.37832036e-01,\n",
       "           4.41086338e-01, -3.25089987e-01],\n",
       "         [-1.62964123e-04,  8.46422401e-02,  3.55334009e-01,\n",
       "           4.28398803e-02, -6.53170361e-02],\n",
       "         [ 7.10697948e-02,  2.81244824e-01,  3.44004787e-01,\n",
       "          -4.86517593e-04, -3.44738922e-01],\n",
       "         [ 6.95192071e-02,  8.41311523e-02,  2.06213140e-01,\n",
       "          -3.02257260e-04, -3.69496788e-01],\n",
       "         [-5.28555004e-05,  4.17738511e-01,  3.34043577e-01,\n",
       "           3.01131683e-01, -5.11205607e-01],\n",
       "         [ 4.93804266e-01,  6.64176326e-03,  3.44232300e-01,\n",
       "           4.83617351e-01, -2.89167485e-01],\n",
       "         [-5.14132817e-05,  3.05935081e-01,  3.80035406e-01,\n",
       "           4.61323476e-01,  1.89351133e-04],\n",
       "         [ 5.45200454e-01,  4.01485571e-01,  8.35377407e-02,\n",
       "           9.13696521e-02, -2.78607568e-01],\n",
       "         [ 4.05719881e-01,  4.13934501e-01,  1.63340524e-01,\n",
       "           7.76744094e-02,  2.21259173e-04],\n",
       "         [ 9.13184476e-02,  1.02812397e-01,  8.02616377e-05,\n",
       "          -2.61634695e-05, -6.07398499e-02],\n",
       "         [-1.39180626e-05,  4.78175789e-01,  3.36164172e-01,\n",
       "           4.51156394e-01, -4.06562970e-01],\n",
       "         [ 7.35562017e-05,  2.58376136e-01,  2.18226181e-03,\n",
       "           2.19768189e-01, -2.07661595e-01]])])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
=======
      "\n",
      "rebuilding\n",
      "\n",
      "cp_als time:  1  seconds\n",
      "rebuild time:  0  seconds\n",
      "fit time:  0  seconds\n",
      "fit  0.8646254090593688\n",
      "SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  2  0]\n",
      " [ 0  2  1]\n",
      " [ 0  2  5]\n",
      " ...\n",
      " [19 28 26]\n",
      " [19 28 33]\n",
      " [19 28 39]], shape=(5245, 3), dtype=int64), values=tf.Tensor([1.3725675  0.16821049 1.6796459  ... 1.6558305  3.746104   1.0498344 ], shape=(5245,), dtype=float32), dense_shape=tf.Tensor([20 30 50], shape=(3,), dtype=int64))\n"
     ]
>>>>>>> 688865f04aff03f46b82626f7f5095bc4c4908c6
    }
   ],
   "source": [
    "before = datetime.now()\n",
    "cpd = cp_als(st, rank,n_iter_max=50)\n",
    "after = datetime.now()\n",
    "print(\"\\nrebuilding\\n\")\n",
    "rebuilt = rebuild(cpd,shape,rank)\n",
    "after2 = datetime.now()\n",
    "fit_st_rebuilt = fit(st,rebuilt)\n",
    "after3 = datetime.now()\n",
    "print(\"cp_als time: \",  (after-before).seconds, \" seconds\") # there is about a 20 - 30x speedup between the\n",
    "print(\"rebuild time: \",  (after2-after).seconds, \" seconds\")\n",
    "print(\"fit time: \",  (after3-after2).seconds, \" seconds\")\n",
    "print(\"fit \", fit_st_rebuilt)\n",
    "# print(\"fit1 \", fit(st,rebuilt)) fit2 is the exact same thing but way faster\n",
    "# print(cpd)\n",
    "# print(to_dense(rebuilt))\n",
    "# print(to_dense(st))\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999696928789"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
>>>>>>> 688865f04aff03f46b82626f7f5095bc4c4908c6
   "source": [
    "def test(shape, rank, iters=50, density = 0.01, verbose=True):\n",
    "    t0 = datetime.now()\n",
    "    st = generate_decomposable_sp_tensor(shape, rank, d=density)\n",
    "    t1 = datetime.now()\n",
    "    cpd = cp_als(st, rank,n_iter_max=iters)\n",
    "    t2 = datetime.now()\n",
    "    rebuilt = rebuild(cpd,shape,rank)\n",
    "    t3 = datetime.now()\n",
    "    fit_st_rebuilt = fit(st,rebuilt)\n",
    "    t4 = datetime.now()\n",
    "    \n",
    "    result_text = '''\n",
    "    +--------------------------------------------\n",
    "    | shape: {}\n",
    "    | rank: {}\n",
    "    | iterations: {}\n",
    "    | density: {}\n",
    "    | actual density: {}\n",
    "    | number of non-zeros: {}\n",
    "    |--------------------------------------------\n",
    "    | time to generate tensor: {} seconds\n",
    "    | time to perform cp_als:  {} seconds\n",
    "    | time to rebuild decomp:  {} seconds\n",
    "    | time to perform fit:     {} seconds\n",
    "    |--------------------------------------------\n",
    "    | fit: {}\n",
    "    +--------------------------------------------\n",
    "    '''.format(shape, rank, iters, density, \n",
    "               (st.values.shape[0]/np.prod(shape)),\n",
    "               st.values.shape[0],(t1-t0).seconds, \n",
    "               (t2-t1).seconds, (t3-t2).seconds, \n",
    "               (t4-t3).seconds, fit_st_rebuilt)\n",
    "    if verbose:\n",
    "        print(result_text)\n",
    "    res = {\n",
    "        \"shape\":shape,\n",
    "        \"rank\":rank,\n",
    "        \"iterations\":iters,\n",
    "        \"density\":density,\n",
    "        \"actual_density\": (st.values.shape[0]/np.prod(shape)),\n",
    "        \"non_zeros\":st.values.shape[0],\n",
    "        \"tensor_generate_time\":(t1-t0).seconds,\n",
    "        \"cp_als_time\":(t2-t1).seconds,\n",
    "        \"redbuild_time\":(t3-t2).seconds,\n",
    "        \"fit_time\":(t4-t3).seconds,\n",
    "        \"fit\":fit_st_rebuilt\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9997538004053812"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
=======
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test((400,5000,400), 22, iters=50, density=0.00000007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
>>>>>>> 688865f04aff03f46b82626f7f5095bc4c4908c6
   "source": [
    "# Brute force way for rebuilding mode-3 tensors\n",
    "\n",
    "# @njit(parallel=True)\n",
    "# def rebuild_3(kruskal_tensor, dimensions, rank):\n",
    "#     if len(dimensions)!= 3:\n",
    "#         return\n",
    "#     indices = []\n",
    "#     values = []\n",
    "#     factors = kruskal_tensor[1]\n",
    "#     weights = kruskal_tensor[0][0]\n",
    "#     fi = factors[0]\n",
    "#     fj = factors[1]\n",
    "#     fk = factors[2]\n",
    "#     for i in range(dimensions[0]):\n",
    "#         print(i, end=\"\\r\")\n",
    "#         for j in range(dimensions[1]):\n",
    "#             for k in range(dimensions[2]):\n",
    "#                 varr = fi[i] * fj[j] * fk[k] * weights\n",
    "#                 v = 0\n",
    "#                 for val in varr:\n",
    "#                     v+= val\n",
    "#                 if v != 0:\n",
    "#                     indices.append([i,j,k])\n",
    "#                     values.append(v)\n",
    "#     return tf.SparseTensor(indices=indices, values=values, dense_shape=dimensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A robust testing framework should test:\n",
    "    tensors of varying number of dimensions\n",
    "    tensors of various sizes\n",
    "    tensors of varying rank\n",
    "    tensors of varying sparsity\n",
    "    tensors that are not perfectly decomposable\n",
    "    running a variety of different ranks\n",
    "    running a variety of different max number of iterations\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
