{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore'); #tensorflow gives me weird stuff\n",
    "import numpy as np;\n",
    "import tensorflow as tf;\n",
    "from numpy import matmul as mul\n",
    "from numpy.linalg import norm as norm\n",
    "from scipy import sparse\n",
    "from tensorflow.sparse import to_dense\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand(factors, weights, dim_no, cur_idx, cur_prod, all_vals, rank):\n",
    "    #this method just writes to all values, so all values needs to be saved somewhere\n",
    "    if dim_no == len(factors):\n",
    "        value = 0;\n",
    "        for r in range(rank):\n",
    "            value += cur_prod[r] * weights[0][r]\n",
    "        if(value != 0.0):\n",
    "            all_vals.append((cur_idx,value)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)): # go through all rows\n",
    "            cp = np.ndarray.copy(cur_prod);\n",
    "            for r in range(rank): # go through each rank\n",
    "                cp[r] *= cur_fact[i][r]\n",
    "            expand(factors, weights, dim_no + 1, cur_idx + [i], cp, all_vals, rank)\n",
    "            \n",
    "def rebuild_sp_tensor_from_factors(kruskal_tensor, dimensions, rank):\n",
    "    factors = kruskal_tensor[1]\n",
    "    weights = kruskal_tensor[0]\n",
    "    all_values = []\n",
    "    expand(factors, weights, 0, [], np.ones(rank), all_values, rank)\n",
    "    indices = [a[0] for a in all_values]\n",
    "    values = [a[1] for a in all_values]\n",
    "    shape = dimensions\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_factors(dimensions, rank, d = 0.8):\n",
    "    factors = [sparse.random(dim,rank,density=d).A for dim in dimensions]\n",
    "    return factors\n",
    "\n",
    "def expand_random_factors(factors, dim_no, cur_idx, cur_prod, all_vals, rank):\n",
    "    #this method just writes to all values, so all values needs to be saved somewhere\n",
    "    if dim_no == len(factors):\n",
    "        value = sum(cur_prod) * (3.16**dim_no) # root 10. makes the numbers closer to [0-1]\n",
    "        if(value != 0.0):\n",
    "            all_vals.append((cur_idx,value)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)):\n",
    "            cp = np.ndarray.copy(cur_prod);\n",
    "            for r in range(rank):\n",
    "                cp[r] *= cur_fact[i][r]\n",
    "            expand_random_factors(factors, dim_no + 1, cur_idx + [i], cp, all_vals, rank)\n",
    "            \n",
    "def generate_decomposable_sp_tensor(dimensions, rank):\n",
    "    factors = generate_random_factors(dimensions, rank)\n",
    "    all_values = []\n",
    "    expand_random_factors(factors, 0, [], np.ones(rank), all_values, rank)\n",
    "    indices = [a[0] for a in all_values]\n",
    "    values = [a[1] for a in all_values]\n",
    "    shape = dimensions\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    return st\n",
    "\n",
    "def generate_random_sp_tensor(dimensions, d = 0.2):\n",
    "    nd = len(dimensions)\n",
    "    num_items = min(100000 , (int)(np.prod(dimensions) * d))    \n",
    "    idxs = set()\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        rand = np.random.rand(nd) #gives us a random index\n",
    "        index = tuple(np.trunc(np.multiply(rand,dimensions)).astype(int))\n",
    "        idxs.add(index)\n",
    "        \n",
    "    indices = list(idxs)\n",
    "    values = np.random.rand(len(indices))\n",
    "    indices.sort()\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=dimensions)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_norm(st):\n",
    "    return (sum([x**2 for x in st.values.numpy()])**0.5)\n",
    "\n",
    "def difference_frobenius_norm(spt1, spt2):\n",
    "    idx1 = [tuple(s) for s in spt1.indices.numpy()]\n",
    "    idx2 = [tuple(s) for s in spt2.indices.numpy()]\n",
    "    val1 = spt1.values.numpy()\n",
    "    val2 = spt2.values.numpy() \n",
    "    s1 = {idx1[i]:val1[i] for i in range(len(idx1))}\n",
    "    s2 = {idx2[i]:val2[i] for i in range(len(idx2))}\n",
    "    sum_sq = 0;\n",
    "    for i in idx1:\n",
    "        if i in idx2:\n",
    "            sum_sq += (s1[i] - s2[i]) ** 2\n",
    "        else:\n",
    "            sum_sq += s1[i] ** 2\n",
    "    for i in idx2:\n",
    "        if i in idx1:\n",
    "            sum_sq += 0\n",
    "        else:\n",
    "            sum_sq += s2[i] ** 2\n",
    "    return sum_sq ** 0.5\n",
    "\n",
    "def fit(spt1, spt2):\n",
    "    return 1 - (difference_frobenius_norm(spt1,spt2)/tensor_norm(spt1))\n",
    "\n",
    "def easy_fit(spt1,spt2):\n",
    "    return 1 - (abs(tensor_norm(spt1)-tensor_norm(spt2))/tensor_norm(spt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mttkrp(X, factors, n, rank, dims):    \n",
    "    output = np.zeros((dims[n],rank))\n",
    "    indices = X.indices.numpy()\n",
    "    values = X.values.numpy()\n",
    "    \n",
    "    for l in range(len(values)):\n",
    "        cur_index = indices[l]\n",
    "        prod = [values[l]]*rank #makes the value into a row\n",
    "\n",
    "        for mode,cv in enumerate(cur_index): #does elementwise row multiplications\n",
    "            if(mode != n):\n",
    "                prod *= factors[mode][cv]\n",
    "                \n",
    "        output[cur_index[n]] += prod\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Decomposition\n",
    "\n",
    "def cp_als(X, rank, n_iter_max = 50):\n",
    "    \n",
    "    dims = X.shape.as_list()\n",
    "    nd = len(dims)\n",
    "    factors = [np.random.random((d,rank)) for d in dims]\n",
    "    weights = np.ones((1,rank))\n",
    "    \n",
    "    for iteration in range(n_iter_max): \n",
    "        print(iteration , end=\"\\r\")\n",
    "        for n in range(nd):\n",
    "            \n",
    "            #the following block calculates inverse of the hadamard product\n",
    "            h = mul(weights.T,weights)\n",
    "            for i,f in enumerate(factors):\n",
    "                if i != n:\n",
    "                    h *= mul(f.T,f)\n",
    "            vinv = np.linalg.pinv(h)\n",
    "            \n",
    "            #the following block calculates An by doing MTTKRP and multiplying it by the inverse of the hadamard\n",
    "            mk = mttkrp(X, factors, n, rank, dims)\n",
    "            wmk = np.multiply(mk, weights[0]) #handling the weights\n",
    "            An = mul(wmk,vinv)\n",
    "            \n",
    "            #the following block normalizes the columns and stored\n",
    "            weight = norm(An,axis=0)\n",
    "            b = np.where(weight<1e-12, 1, weight)\n",
    "            weights[0] *= b\n",
    "            An /= b\n",
    "            \n",
    "            factors[n] = An\n",
    "            \n",
    "    return weights, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1 = [18,27,12]\n",
    "rank = 5\n",
    "st1 = generate_decomposable_sp_tensor(shape1, rank)\n",
    "#st1 = generate_random_sp_tensor(shape1)\n",
    "# to_dense(st1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for dimensions in range(2,20):\n",
    "#     for rank in range(1,20):\n",
    "#         shp = list(np.random.randint(2,100,size=(dimensions)))\n",
    "#         st = generate_decomposable_sp_tensor(shp, rank)\n",
    "#         v = len(st.values.numpy())\n",
    "#         decomp = cp_als(st, rank)\n",
    "#         rebuilt = rebuild_sp_tensor_from_factors(decomp, shp, rank)\n",
    "#         fit_val = fit(st,rebuilt)\n",
    "#         print(\"fit: {},\\trank: {},\\tshape: {}\\tnumber of nonzeros: {}\".format(fit_val, rank, shp,v))\n",
    "\n",
    "'''\n",
    "A robust testing framework should test:\n",
    "    tensors of varying number of dimensions\n",
    "    tensors of various sizes\n",
    "    tensors of varying rank\n",
    "    tensors of varying sparsity\n",
    "    tensors that are not perfectly decomposable\n",
    "    running a variety of different ranks\n",
    "    running a variety of different max number of iterations\n",
    "'''\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\r"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a8c97a003341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcpd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcp_als\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrebuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrebuild_sp_tensor_from_factors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcpd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(difference_frobenius_norm(st1, rebuilt)/tensor_norm(st1))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-18cf2fecc883>\u001b[0m in \u001b[0;36mcp_als\u001b[0;34m(X, rank, n_iter_max)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m#the following block normalizes the columns and stored\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0;36m1e-12\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m1e12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mAn\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "cpd = cp_als(st1, rank)\n",
    "rebuilt = rebuild_sp_tensor_from_factors(cpd, shape1, rank)\n",
    "# print(difference_frobenius_norm(st1, rebuilt)/tensor_norm(st1))\n",
    "cpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999965033467882"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "easy_fit(st1,rebuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9973555162699668"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(st1,rebuilt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
