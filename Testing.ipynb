{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import warnings;\n",
    "warnings.filterwarnings('ignore'); #tensorflow gives me weird stuff\n",
    "import numpy as np;\n",
    "import tensorflow as tf;\n",
    "from numpy import matmul as mul\n",
    "from numpy.linalg import norm as norm\n",
    "from scipy import sparse\n",
    "from tensorflow.sparse import to_dense\n",
    "from numba import prange,njit,jit\n",
    "from numba.typed import List\n",
    "from datetime import datetime\n",
    "# tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def expand(factors, weights, dim_no, cur_idx, all_vals, rank):\n",
    "    \n",
    "    if dim_no == len(factors):\n",
    "#         print(cur_idx)\n",
    "        value = np.ones(rank)\n",
    "        for j,w in enumerate(weights):                \n",
    "            value[j] = w\n",
    "        for i in range(dim_no):\n",
    "            ci = cur_idx[i]\n",
    "            f = factors[i][ci]\n",
    "            for j,v in enumerate(value):                \n",
    "                value[j] = v * f[j]\n",
    "        s = 0.0\n",
    "        for val in value:\n",
    "            s += val\n",
    "        if(s != 0.0):\n",
    "            t = np.ones(dim_no, dtype=np.int64)\n",
    "            for k in range(dim_no):\n",
    "                t[k] = cur_idx[k]\n",
    "            all_vals.append((t,s)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)):\n",
    "            cur_idx[dim_no] = i\n",
    "            expand(factors, weights, dim_no + 1, cur_idx, all_vals, rank)\n",
    "\n",
    "def rebuild(kruskal_tensor, dimensions, rank):\n",
    "    factors = kruskal_tensor[1]\n",
    "    weights = kruskal_tensor[0][0]\n",
    "    cur_idx = np.zeros(len(dimensions), dtype=\"int64\")\n",
    "    av = [(cur_idx, 0.0)] # list(Tuple(array(int64, 1d, C), float64)))\n",
    "    \n",
    "    expand(factors, weights, 0, cur_idx, av, rank)\n",
    "    \n",
    "    av = av[1:]\n",
    "    indexes = [a[0] for a in av]\n",
    "    vals = [a[1] for a in av]\n",
    "#     print(indexes)\n",
    "#     print(vals)\n",
    "    st = tf.SparseTensor(indices=indexes, values=vals, dense_shape=dimensions)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_factors(dimensions, rank, d = 0.1):\n",
    "    factors = [sparse.random(dim,rank,density=d).A for dim in dimensions]\n",
    "    return factors\n",
    "\n",
    "@njit(parallel=True)\n",
    "def l1_erf(factors, cur_idx, all_vals, rank):\n",
    "    cur_fact = factors[0]\n",
    "    for i in prange(len(cur_fact)):\n",
    "        cur_idx[0] = i\n",
    "        expand_random_factors(factors, 1, cur_idx, all_vals, rank)\n",
    "        \n",
    "@njit\n",
    "def expand_random_factors(factors, dim_no, cur_idx, all_vals, rank):\n",
    "    #this method just writes to all values, so all values needs to be saved somewhere\n",
    "    if dim_no == len(factors):\n",
    "        value = np.ones(rank)\n",
    "        for i in range(dim_no):\n",
    "            ci = cur_idx[i]\n",
    "            f = factors[i][ci]\n",
    "            for j,v in enumerate(value):                \n",
    "                value[j] = v * f[j]\n",
    "        s = 0.0\n",
    "        for val in value:\n",
    "            s += val\n",
    "        v = s * (3.16**dim_no)\n",
    "        if(v != 0.0):\n",
    "            t = np.ones(dim_no, dtype=np.int64)\n",
    "            t *= cur_idx\n",
    "            all_vals.append((t,v)) \n",
    "    else:\n",
    "        cur_fact = factors[dim_no]\n",
    "        for i in range(len(cur_fact)):\n",
    "            cur_idx[dim_no] = i\n",
    "            expand_random_factors(factors, dim_no + 1, cur_idx, all_vals, rank)\n",
    "            \n",
    "def generate_decomposable_sp_tensor(dimensions, rank, d = 0.1):\n",
    "    nd = len(dimensions)\n",
    "    factor_d = (d/rank) ** (1/nd)\n",
    "    \n",
    "    factors = generate_random_factors(dimensions, rank, factor_d)\n",
    "    cur_idx = np.zeros(len(dimensions), dtype=\"int64\")\n",
    "    all_values = [(cur_idx, 0.0)] # list(Tuple(array(int64, 1d, C), float64)))\n",
    "    expand_random_factors(factors, 0, cur_idx, all_values, rank)\n",
    "    all_values = all_values[1:]\n",
    "    indices = [a[0] for a in all_values]\n",
    "    values = [a[1] for a in all_values]\n",
    "    shape = dimensions\n",
    "#     print(indices)\n",
    "#     print(values)\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=shape)\n",
    "    return st\n",
    "\n",
    "def generate_random_sp_tensor(dimensions, d = 0.2):\n",
    "    nd = len(dimensions)\n",
    "    num_items = min(100000 , (int)(np.prod(dimensions) * d))    \n",
    "    idxs = set()\n",
    "    \n",
    "    for i in range(num_items):\n",
    "        rand = np.random.rand(nd) #gives us a random index\n",
    "        index = tuple(np.trunc(np.multiply(rand,dimensions)).astype(int))\n",
    "        idxs.add(index)\n",
    "        \n",
    "    indices = list(idxs)\n",
    "    values = np.random.rand(len(indices))\n",
    "    indices.sort()\n",
    "    st = tf.SparseTensor(indices=indices, values=values, dense_shape=dimensions)\n",
    "    return st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_norm(st):\n",
    "    return (sum([x**2 for x in st.values.numpy()])**0.5)\n",
    "\n",
    "def diff(spt1, spt2):\n",
    "    idx1 = [tuple(s) for s in spt1.indices.numpy()]\n",
    "    idx2 = [tuple(s) for s in spt2.indices.numpy()]\n",
    "    val1 = spt1.values.numpy()\n",
    "    val2 = spt2.values.numpy() \n",
    "    s1 = [(idx1[i],val1[i]) for i in range(len(idx1))]\n",
    "    s2 = [(idx2[i],val2[i]) for i in range(len(idx2))]\n",
    "    s1.sort()\n",
    "    s2.sort()\n",
    "    i1 = 0\n",
    "    i2 = 0\n",
    "    l1 = len(s1)\n",
    "    l2 = len(s2)\n",
    "    \n",
    "    sum_sq = 0\n",
    "    while(i1 < l1 and i2 < l2):\n",
    "        p1 = s1[i1]\n",
    "        p2 = s2[i2]\n",
    "        if p1[0] == p2[0]:\n",
    "            sum_sq += (p1[1] - p2[1]) ** 2\n",
    "            i1 += 1\n",
    "            i2 += 1\n",
    "        elif p1[0] < p2[0]:\n",
    "            sum_sq += p1[1] ** 2\n",
    "            i1 += 1\n",
    "        else:\n",
    "            sum_sq += p2[1] ** 2\n",
    "            i2 += 1\n",
    "    if(i1 == l1):\n",
    "        while(i2 < l2):\n",
    "            p2 = s2[i2]\n",
    "            sum_sq += p2[1] ** 2\n",
    "            i2 += 1\n",
    "    else:\n",
    "        while(i1 < l1):\n",
    "            p1 = s1[i1]\n",
    "            sum_sq += p1[1] ** 2\n",
    "            i1 += 1\n",
    "            \n",
    "    return sum_sq ** 0.5\n",
    "            \n",
    "def fit(spt1,spt2):\n",
    "    return 1 - (diff(spt1,spt2)/tensor_norm(spt1))\n",
    "\n",
    "def easy_fit(spt1,spt2):\n",
    "    return 1 - (abs(tensor_norm(spt1)-tensor_norm(spt2))/tensor_norm(spt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mttkrp2(X, factors, n, rank, dims):    \n",
    "    output = np.zeros((dims[n],rank))\n",
    "    indices = X.indices.numpy()\n",
    "    values = X.values.numpy()\n",
    "    \n",
    "    for l in prange(len(values)):\n",
    "        cur_index = indices[l]\n",
    "        prod = [values[l]]*rank #makes the value into a row\n",
    "\n",
    "        for mode,cv in enumerate(cur_index): #does elementwise row multiplications\n",
    "            if(mode != n):\n",
    "                prod *= factors[mode][cv]      \n",
    "        output[cur_index[n]] += prod\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit(parallel=True)\n",
    "def mttkrp(values, indices, factors, n, rank, dims):    \n",
    "    output = np.zeros((dims[n],rank))\n",
    "\n",
    "    for l in prange(len(values)):\n",
    "        cur_index = indices[l]\n",
    "        prod = [values[l]]*rank #makes the value into a row\n",
    "\n",
    "        for mode,cv in enumerate(cur_index): #does elementwise row multiplications\n",
    "            if(mode != n):\n",
    "                for r in range(rank):\n",
    "                    prod[r] *= factors[mode][cv][r]\n",
    "            \n",
    "        for r in range(rank):\n",
    "            output[cur_index[n]][r] += prod[r]       \n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CP Decomposition\n",
    "\n",
    "def cp_als(X, rank, n_iter_max = 50):\n",
    "    \n",
    "    dims = X.shape.as_list()\n",
    "    nd = len(dims)\n",
    "    factors = [np.random.random((d,rank)) for d in dims]\n",
    "    weights = np.ones((1,rank))\n",
    "    \n",
    "    for iteration in range(n_iter_max): \n",
    "#         print(iteration+1 , end=\"\\r\")\n",
    "        for n in range(nd):\n",
    "            \n",
    "            #the following block calculates inverse of the hadamard product\n",
    "            h = mul(weights.T,weights)\n",
    "            for i,f in enumerate(factors):\n",
    "                if i != n:\n",
    "                    h *= mul(f.T,f)\n",
    "            vinv = np.linalg.pinv(h)\n",
    "            \n",
    "            #the following block calculates An by doing MTTKRP and multiplying it by the inverse of the hadamard\n",
    "            vals = X.values.numpy()\n",
    "            idxs = X.indices.numpy()\n",
    "            mk = mttkrp(vals, idxs, factors, n, rank, dims)\n",
    "#             mk = mttkrp2(X, factors, n, rank, dims)\n",
    "            wmk = np.multiply(mk, weights[0]) #handling the weights\n",
    "            An = mul(wmk,vinv)\n",
    "            \n",
    "            #the following block normalizes the columns and stored\n",
    "            weight = norm(An,axis=0)\n",
    "            b = np.where(weight<1e-12, 1, weight)\n",
    "            weights[0] *= b\n",
    "            An /= b\n",
    "            \n",
    "            factors[n] = An\n",
    "            \n",
    "    return weights, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (20,30,50)\n",
    "rank = 19\n",
    "density = 0.2\n",
    "before = datetime.now()\n",
    "st = generate_decomposable_sp_tensor(shape, rank, d=density)\n",
    "after = datetime.now()\n",
    "print(\"time: \",  (after-before).seconds, \" seconds\")\n",
    "print(\"actual density: \", st.values.shape[0]/np.prod(shape), \" vs given density \", density)\n",
    "# st = generate_random_sp_tensor(shape, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "before = datetime.now()\n",
    "cpd = cp_als(st, rank,n_iter_max=50)\n",
    "after = datetime.now()\n",
    "print(\"\\nrebuilding\\n\")\n",
    "rebuilt = rebuild(cpd,shape,rank)\n",
    "after2 = datetime.now()\n",
    "fit_st_rebuilt = fit(st,rebuilt)\n",
    "after3 = datetime.now()\n",
    "print(\"cp_als time: \",  (after-before).seconds, \" seconds\") # there is about a 20 - 30x speedup between the\n",
    "print(\"rebuild time: \",  (after2-after).seconds, \" seconds\")\n",
    "print(\"fit time: \",  (after3-after2).seconds, \" seconds\")\n",
    "print(\"fit \", fit_st_rebuilt)\n",
    "# print(\"fit1 \", fit(st,rebuilt)) fit2 is the exact same thing but way faster\n",
    "# print(cpd)\n",
    "# print(to_dense(rebuilt))\n",
    "# print(to_dense(st))\n",
    "print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(shape, rank, iters=50, density = 0.01, verbose=True):\n",
    "    t0 = datetime.now()\n",
    "    st = generate_decomposable_sp_tensor(shape, rank, d=density)\n",
    "    t1 = datetime.now()\n",
    "    cpd = cp_als(st, rank,n_iter_max=iters)\n",
    "    t2 = datetime.now()\n",
    "    rebuilt = rebuild(cpd,shape,rank)\n",
    "    t3 = datetime.now()\n",
    "    fit_st_rebuilt = fit(st,rebuilt)\n",
    "    t4 = datetime.now()\n",
    "    \n",
    "    result_text = '''\n",
    "    +--------------------------------------------\n",
    "    | shape: {}\n",
    "    | rank: {}\n",
    "    | iterations: {}\n",
    "    | density: {}\n",
    "    | actual density: {}\n",
    "    | number of non-zeros: {}\n",
    "    |--------------------------------------------\n",
    "    | time to generate tensor: {} seconds\n",
    "    | time to perform cp_als:  {} seconds\n",
    "    | time to rebuild decomp:  {} seconds\n",
    "    | time to perform fit:     {} seconds\n",
    "    |--------------------------------------------\n",
    "    | fit: {}\n",
    "    +--------------------------------------------\n",
    "    '''.format(shape, rank, iters, density, \n",
    "               (st.values.shape[0]/np.prod(shape)),\n",
    "               st.values.shape[0],(t1-t0).seconds, \n",
    "               (t2-t1).seconds, (t3-t2).seconds, \n",
    "               (t4-t3).seconds, fit_st_rebuilt)\n",
    "    if verbose:\n",
    "        print(result_text)\n",
    "    res = {\n",
    "        \"shape\":shape,\n",
    "        \"rank\":rank,\n",
    "        \"iterations\":iters,\n",
    "        \"density\":density,\n",
    "        \"actual_density\": (st.values.shape[0]/np.prod(shape)),\n",
    "        \"non_zeros\":st.values.shape[0],\n",
    "        \"tensor_generate_time\":(t1-t0).seconds,\n",
    "        \"cp_als_time\":(t2-t1).seconds,\n",
    "        \"redbuild_time\":(t3-t2).seconds,\n",
    "        \"fit_time\":(t4-t3).seconds,\n",
    "        \"fit\":fit_st_rebuilt\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test((400,5000,400), 22, iters=50, density=0.00000007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brute force way for rebuilding mode-3 tensors\n",
    "\n",
    "# @njit(parallel=True)\n",
    "# def rebuild_3(kruskal_tensor, dimensions, rank):\n",
    "#     if len(dimensions)!= 3:\n",
    "#         return\n",
    "#     indices = []\n",
    "#     values = []\n",
    "#     factors = kruskal_tensor[1]\n",
    "#     weights = kruskal_tensor[0][0]\n",
    "#     fi = factors[0]\n",
    "#     fj = factors[1]\n",
    "#     fk = factors[2]\n",
    "#     for i in range(dimensions[0]):\n",
    "#         print(i, end=\"\\r\")\n",
    "#         for j in range(dimensions[1]):\n",
    "#             for k in range(dimensions[2]):\n",
    "#                 varr = fi[i] * fj[j] * fk[k] * weights\n",
    "#                 v = 0\n",
    "#                 for val in varr:\n",
    "#                     v+= val\n",
    "#                 if v != 0:\n",
    "#                     indices.append([i,j,k])\n",
    "#                     values.append(v)\n",
    "#     return tf.SparseTensor(indices=indices, values=values, dense_shape=dimensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A robust testing framework should test:\n",
    "    tensors of varying number of dimensions\n",
    "    tensors of various sizes\n",
    "    tensors of varying rank\n",
    "    tensors of varying sparsity\n",
    "    tensors that are not perfectly decomposable\n",
    "    running a variety of different ranks\n",
    "    running a variety of different max number of iterations\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
